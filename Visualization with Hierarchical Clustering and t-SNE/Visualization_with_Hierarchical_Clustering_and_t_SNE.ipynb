{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing Hierarchies"
      ],
      "metadata": {
        "id": "MbVX-klWVTGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The dendrogram of a hierarchical clustering**"
      ],
      "metadata": {
        "id": "bVrNSWX_Yk4r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AE6GurvyVNx2"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "\n",
        "Hierarchical clustering proceeds in steps. In the beginning, every country is its own cluster - so there are as many clusters as there are countries!\n",
        "At each step, the two closest clusters are merged. This decreases the number of clusters, and eventually, there is only one cluster left,\n",
        "and it contains all the countries. This process is actually a particular type of hierarchical clustering called \"agglomerative clustering\"\n",
        "\n",
        "\n",
        "\n",
        "The entire process of the hierarchical clustering is encoded in the dendrogram. At the bottom, each country is in a cluster of its own.\n",
        "The clustering then proceeds from the bottom up. Clusters are represented as vertical lines, and a joining of vertical lines indicates a merging of clusters\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Import:\n",
        "linkage and dendrogram from scipy.cluster.hierarchy.\n",
        "matplotlib.pyplot as plt.\n",
        "\n",
        "\n",
        "Perform hierarchical clustering on samples using the linkage() function with the method='complete' keyword argument. Assign the result to mergings.\n",
        "Plot a dendrogram using the dendrogram() function on mergings. Specify the keyword arguments labels=varieties, leaf_rotation=90, and leaf_font_size=6\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Perform the necessary imports\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate the linkage: mergings\n",
        "mergings = linkage(samples, method = 'complete')\n",
        "\n",
        "# Plot the dendrogram, using varieties as labels\n",
        "dendrogram(mergings,\n",
        "           labels=varieties,\n",
        "           leaf_rotation=90,\n",
        "           leaf_font_size=6,\n",
        ")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AQBqLcO1ZgHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Hierarchies of stocks\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "In chapter 1, we used k-means clustering to cluster companies according to their stock price movements. Now, you'll perform hierarchical clustering of the companies.\n",
        "We are given a NumPy array of price movements movements, where the rows correspond to companies, and a list of the company names companies.\n",
        "SciPy hierarchical clustering doesn't fit into a sklearn pipeline, so we'll need to use the normalize() function from sklearn.preprocessing instead of Normalizer\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Import normalize from sklearn.preprocessing.\n",
        "Rescale the price movements for each stock by using the normalize() function on movements.\n",
        "Apply the linkage() function to normalized_movements, using 'complete' linkage, to calculate the hierarchical clustering. Assign the result to mergings.\n",
        "Plot a dendrogram of the hierarchical clustering, using the list companies of company names as the labels. In addition, specify the leaf_rotation=90, and leaf_font_size=6 keyword arguments.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Import normalize\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "# Normalize the movements: normalized_movements\n",
        "normalized_movements = normalize(movements)\n",
        "\n",
        "# Calculate the linkage: mergings\n",
        "mergings = linkage(normalized_movements, method = 'complete')\n",
        "\n",
        "# Plot the dendrogram\n",
        "dendrogram(mergings,\n",
        "           labels=companies,\n",
        "           leaf_rotation=90,\n",
        "           leaf_font_size=6,\n",
        ")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "10TzGA_Af9gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cluster labels in Hierarchical Clustering"
      ],
      "metadata": {
        "id": "piUEMd8kgqgz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Intermediate Clusterings & Height **"
      ],
      "metadata": {
        "id": "R6YsRR2fuR4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "1) What is an Intermediate Clustering?\n",
        "----------------------------------------\n",
        "At different points in the process, we can stop merging and take the clusters as they are.\n",
        "\n",
        "\n",
        "2) What Does the Height in a Dendrogram Mean?\n",
        "----------------------------------------------\n",
        "The y-axis of the dendrogram shows the distance between clusters when they merge.\n",
        "\n",
        "If two clusters merge at height 6, it means they were 6 units apart.\n",
        "\n",
        "The bigger the height, the less similar the clusters were before merging\n",
        "\n",
        "\n",
        "3) How to Use This in Practice?\n",
        "-------------------------------------\n",
        "We can choose a height on the dendrogram to decide how many clusters we want.\n",
        "\n",
        "If we stop merging at a lower height, we get many, small clusters.\n",
        "If we stop merging at a higher height, we get fewer, larger clusters.\n",
        "\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "3pintWxpu89h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distance Between Clusters**"
      ],
      "metadata": {
        "id": "AGGcAqSDwxrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "\n",
        "1) How Do We Measure the Distance Between Clusters?\n",
        "--------------------------------------------------------\n",
        "When grouping things together in hierarchical clustering, we need to decide how to measure the distance between two clusters. This is called the \"linkage method\".\n",
        "\n",
        "\n",
        "\n",
        "\"Complete linkage\" means:\n",
        "-------------------------------\n",
        "The distance between two clusters is the largest distance between any two points (one from each cluster).\n",
        "This ensures that clusters stay compact and don’t have very distant points inside them.\n",
        "\n",
        "\n",
        "Example:\n",
        "\n",
        "two groups (clusters):\n",
        "\n",
        "Cluster 1: A (160 cm), B (170 cm)\n",
        "Cluster 2: C (180 cm), D (190 cm)\n",
        "\n",
        "Now, we want to measure the distance between these two clusters.\n",
        "\n",
        "Step 1: Find All Possible Distances\n",
        "We check the height differences between every student from Cluster 1 and every student from Cluster 2:\n",
        "\n",
        "A (160 cm) vs. C (180 cm) → 20 cm\n",
        "A (160 cm) vs. D (190 cm) → 30 cm\n",
        "B (170 cm) vs. C (180 cm) → 10 cm\n",
        "B (170 cm) vs. D (190 cm) → 20 cm\n",
        "\n",
        "Step 2: Choose the Maximum Distance\n",
        "The largest difference is 30 cm, so the distance between these two clusters is 30 cm.\n",
        "\n",
        "\n",
        "Some other linkages:\n",
        "------------------------\n",
        "\n",
        "Single linkage: Uses the smallest distance between two points.\n",
        "Average linkage: Uses the average distance between all pairs of points.\n",
        "Centroid linkage: Uses the distance between cluster centers.\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Zuu4jQEogvDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Import linkage and dendrogram from scipy.cluster.hierarchy.\n",
        "Perform hierarchical clustering on samples using the linkage() function with the method='single' keyword argument. Assign the result to mergings.\n",
        "Plot a dendrogram of the hierarchical clustering, using the list country_names as the labels. In addition, specify the leaf_rotation=90, and leaf_font_size=6 keyword arguments as you have done earlier.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Perform the necessary imports\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "\n",
        "# Calculate the linkage: mergings\n",
        "mergings = linkage(samples, method = 'single')\n",
        "\n",
        "# Plot the dendrogram\n",
        "dendrogram(mergings,\n",
        "           labels=country_names,\n",
        "           leaf_rotation=90,\n",
        "           leaf_font_size=6,\n",
        ")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gwaSRN7F4iYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Intermediate clusterings\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Displayed is the dendrogram for the hierarchical clustering of the grain samples that you computed earlier. If the hierarchical clustering were stopped\n",
        "at height 6 on the dendrogram, how many clusters would there be?\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from scipy.cluster.hierarchy import linkage\n",
        "mergings = linkage(samples, method='complete')\n",
        "from scipy.cluster.hierarchy import fcluster\n",
        "labels = fcluster(mergings, 6, criterion='distance')\n",
        "print(labels)"
      ],
      "metadata": {
        "id": "SWKJ58eb4xHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Extracting the cluster labels\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Import:\n",
        "pandas as pd.\n",
        "fcluster from scipy.cluster.hierarchy.\n",
        "\n",
        "\n",
        "Perform a flat hierarchical clustering by using the fcluster() function on mergings. Specify a maximum height of 6 and the keyword argument criterion='distance'.\n",
        "Create a DataFrame df with two columns named 'labels' and 'varieties', using labels and varieties, respectively, for the column values. This has been done for you.\n",
        "Create a cross-tabulation ct between df['labels'] and df['varieties'] to count the number of times each grain variety coincides with each cluster label.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Perform the necessary imports\n",
        "import pandas as pd\n",
        "from scipy.cluster.hierarchy import fcluster\n",
        "\n",
        "# Use fcluster to extract labels: labels\n",
        "labels = fcluster(mergings, 6, criterion='distance')\n",
        "\n",
        "# Create a DataFrame with labels and varieties as columns: df\n",
        "df = pd.DataFrame({'labels': labels, 'varieties': varieties})\n",
        "\n",
        "# Create crosstab: ct\n",
        "ct = pd.crosstab(df['labels'], df['varieties'])\n",
        "\n",
        "# Display ct\n",
        "print(ct)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "varieties  Canadian wheat  Kama wheat  Rosa wheat\n",
        "labels\n",
        "1                      14           3           0\n",
        "2                       0           0          14\n",
        "3                       0          11           0\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "wV9IoQDP4xKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# t-SNE for 2 dimensional maps"
      ],
      "metadata": {
        "id": "2ZGw9ZT5-af3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**t-SNE**"
      ],
      "metadata": {
        "id": "Ahh5ze7--iFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "t-SNE (t-distributed Stochastic Neighbor Embedding) is a technique used to visualize high-dimensional data in 2D or 3D.\n",
        "\n",
        "A dataset where each sample has many features (e.g., 50 or more dimensions). We can't easily see patterns in such high dimensions.\n",
        "t-SNE helps by reducing it to just 2 or 3 dimensions, so we can plot it and observe clusters or relationships.\n",
        "\n",
        "\n",
        "\n",
        "The Iris dataset has flowers with 4 measurements:\n",
        "\n",
        "Petal length\n",
        "Petal width\n",
        "Sepal length\n",
        "Sepal width\n",
        "\n",
        "Each flower also belongs to one of 3 species:\n",
        "Setosa\n",
        "Versicolor\n",
        "Virginica\n",
        "\n",
        "Applying t-SNE\n",
        "----------------\n",
        "t-SNE takes the 4D iris data and reduces it to 2D for visualization.\n",
        "\n",
        "It wasn’t told the species labels, just the measurements.\n",
        "After plotting the reduced data in 2D, we see 3 distinct groups when we color them by species.\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "N91OR2-n-d97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**t-SNE Learning Rate**"
      ],
      "metadata": {
        "id": "e70xONyh_A2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "1) Learning Rate in t-SNE\n",
        "------------------------------\n",
        "The learning rate is an important setting in t-SNE that affects how well it maps high-dimensional data to 2D.\n",
        "If the learning rate is too low or too high, the data points might look weird in the plot.\n",
        "\n",
        "Bad learning rate? We will see all points squeezed together in a messy way.\n",
        "Good learning rate? The clusters will be more clearly separated.\n",
        "\n",
        "Note: Usually, trying values between 50 and 200 is enough to get a good result.\n",
        "\n",
        "\n",
        "\n",
        "2) t-SNE Gives Different Results Every Time\n",
        "-----------------------------------------------\n",
        "Unlike some other techniques, t-SNE does not always give the same plot, even if run it on the same data.\n",
        "The axes (X and Y) don’t have a fixed meaning\n",
        "\n",
        "However, the relationships between clusters remain the same.\n",
        "For example, if we run t-SNE on wine varieties, we will see that the three types of wine stay in similar groups, but the whole plot might be rotated or flipped.\n",
        "\n",
        "\n",
        "So, in t-SNE plots, no need to worry about the exact position of clusters—just focus on how the points relate to each other.\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "OBXaDE6i_C0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Import TSNE from sklearn.manifold.\n",
        "Create a TSNE instance called model with learning_rate=200.\n",
        "Apply the .fit_transform() method of model to samples. Assign the result to tsne_features.\n",
        "Select the column 0 of tsne_features. Assign the result to xs.\n",
        "Select the column 1 of tsne_features. Assign the result to ys.\n",
        "Make a scatter plot of the t-SNE features xs and ys. To color the points by the grain variety, specify the additional keyword argument c=variety_numbers.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Import TSNE\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Create a TSNE instance: model\n",
        "model = TSNE(learning_rate=200)\n",
        "\n",
        "# Apply fit_transform to samples: tsne_features\n",
        "tsne_features = model.fit_transform(samples)\n",
        "\n",
        "# Select the 0th feature: xs\n",
        "xs = tsne_features[:,0]\n",
        "\n",
        "# Select the 1st feature: ys\n",
        "ys = tsne_features[:,1]\n",
        "\n",
        "# Scatter plot, coloring by variety_numbers\n",
        "plt.scatter(xs, ys, c = variety_numbers)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bCX9tnECACxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Import TSNE from sklearn.manifold.\n",
        "Create a TSNE instance called model with learning_rate=50.\n",
        "Apply the .fit_transform() method of model to normalized_movements. Assign the result to tsne_features.\n",
        "Select column 0 and column 1 of tsne_features.\n",
        "Make a scatter plot of the t-SNE features xs and ys. Specify the additional keyword argument alpha=0.5.\n",
        "Code to label each point with its company name has been written for you using plt.annotate(), so just hit submit to see the visualization!\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Import TSNE\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Create a TSNE instance: model\n",
        "model = TSNE(learning_rate = 50)\n",
        "\n",
        "# Apply fit_transform to normalized_movements: tsne_features\n",
        "tsne_features = model.fit_transform(normalized_movements)\n",
        "\n",
        "# Select the 0th feature: xs\n",
        "xs = tsne_features[:,0]\n",
        "\n",
        "# Select the 1th feature: ys\n",
        "ys = tsne_features[:,1]\n",
        "\n",
        "# Scatter plot\n",
        "plt.scatter(xs, ys, alpha = 0.5)\n",
        "\n",
        "# Annotate the points\n",
        "for x, y, company in zip(xs, ys, companies):\n",
        "    plt.annotate(company, (x, y), fontsize=5, alpha=0.75)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MotdKgBce42I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}